{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Time series forecasting with ARIMA\n",
    "\n",
    "In this notebook, we demonstrate how to:\n",
    "- prepare time series data for training an ARIMA time series forecasting model\n",
    "- implement a simple ARIMA model to forecast the next HORIZON steps ahead (time *t+1* through *t+HORIZON*) in the time series\n",
    "- evaluate the model \n",
    "\n",
    "\n",
    "The data in this example is taken from the GEFCom2014 forecasting competition<sup>1</sup>. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014. The task is to forecast future values of electricity load. In this example, we show how to forecast one time step ahead, using historical load data only.\n",
    "\n",
    "<sup>1</sup>Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Dependencies\n",
    "Get started by installing some of the required dependencies. These libraries with their corresponding versions are known to work for the solution:\n",
    "\n",
    "* `statsmodels == 0.12.2`\n",
    "* `matplotlib == 3.4.2`\n",
    "* `scikit-learn == 0.24.2`\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "!pip install statsmodels"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from common.utils import load_data, mape\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "energy = load_data('./data')[['load']]\n",
    "energy.head(10)"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot all available load data (January 2012 to Dec 2014)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training and testing data sets\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "train_start_dt = '2014-11-01 00:00:00'\n",
    "test_start_dt = '2014-12-30 00:00:00'    "
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \\\n",
    "    .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \\\n",
    "    .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]\n",
    "test = energy.copy()[energy.index >= test_start_dt][['load']]\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Test data shape: ', test.shape)"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "scaler = MinMaxScaler()\n",
    "train['load'] = scaler.fit_transform(train)\n",
    "train.head(10)"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Original vs scaled data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "energy[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']].rename(columns={'load':'original load'}).plot.hist(bins=100, fontsize=12)\n",
    "train.rename(columns={'load':'scaled load'}).plot.hist(bins=100, fontsize=12)\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also scale the test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "test['load'] = scaler.transform(test)\n",
    "test.head()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement ARIMA method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Specify the number of steps to forecast ahead\n",
    "HORIZON = 3\n",
    "print('Forecasting horizon:', HORIZON, 'hours')"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "order = (4, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)\n",
    "\n",
    "model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a test data point for each HORIZON step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "test_shifted = test.copy()\n",
    "\n",
    "for t in range(1, HORIZON):\n",
    "    test_shifted['load+'+str(t)] = test_shifted['load'].shift(-t, freq='H')\n",
    "    \n",
    "test_shifted = test_shifted.dropna(how='any')\n",
    "test_shifted.head(5)"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make predictions on the test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "%%time\n",
    "training_window = 720 # dedicate 30 days (720 hours) for training\n",
    "\n",
    "train_ts = train['load']\n",
    "test_ts = test_shifted\n",
    "\n",
    "history = [x for x in train_ts]\n",
    "history = history[(-training_window):]\n",
    "\n",
    "predictions = list()\n",
    "\n",
    "# let's user simpler model for demonstration\n",
    "order = (2, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)\n",
    "\n",
    "for t in range(test_ts.shape[0]):\n",
    "    model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(steps = HORIZON)\n",
    "    predictions.append(yhat)\n",
    "    obs = list(test_ts.iloc[t])\n",
    "    # move the training window\n",
    "    history.append(obs[0])\n",
    "    history.pop(0)\n",
    "    print(test_ts.index[t])\n",
    "    print(t+1, ': predicted =', yhat, 'expected =', obs)"
   ],
   "metadata": {
    "scrolled": true
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare predictions to actual load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])\n",
    "eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]\n",
    "eval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')\n",
    "eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()\n",
    "eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])\n",
    "eval_df.head()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the **mean absolute percentage error (MAPE)** over all predictions\n",
    "\n",
    "$$MAPE = \\frac{1}{n} \\sum_{t=1}^{n}|\\frac{actual_t - predicted_t}{actual_t}|$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "if(HORIZON > 1):\n",
    "    eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n",
    "    print(eval_df.groupby('h')['APE'].mean())"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print('One step forecast MAPE: ', (mape(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print('Multi-step forecast MAPE: ', mape(eval_df['prediction'], eval_df['actual'])*100, '%')"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the predictions vs the actuals for the first week of the test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "if(HORIZON == 1):\n",
    "    ## Plotting single step forecast\n",
    "    eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))\n",
    "\n",
    "else:\n",
    "    ## Plotting multi step forecast\n",
    "    plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n",
    "    for t in range(1, HORIZON+1):\n",
    "        plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)\n",
    "    ax = fig.add_subplot(111)\n",
    "    for t in range(1, HORIZON+1):\n",
    "        x = plot_df['timestamp'][(t-1):]\n",
    "        y = plot_df['t+'+str(t)][0:len(x)]\n",
    "        ax.plot(x, y, color='blue', linewidth=4*math.pow(.9,t), alpha=math.pow(0.8,t))\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
   }
  },
  "interpreter": {
   "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
